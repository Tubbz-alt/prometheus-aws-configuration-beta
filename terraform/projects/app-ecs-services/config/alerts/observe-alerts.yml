groups:
- name: RE_Observe
  rules:
  - alert: RE_Observe_Grafana_Down
    expr: up{job="grafana-paas"} == 0
    for: 5m
    labels:
        product: "prometheus"
        severity: "page"
    annotations:
        summary: "Prometheus is not able to scrape Grafana"
        description: "Prometheus has not successfully scraped {{ $labels.job }} in the last 5 minutes. https://grafana-paas.cloudapps.digital/ may be down."
        kibana: "https://kibana.logit.io/s/8fd50110-7b0c-490a-bedf-7544daebbec4/app/kibana#/discover?_g=()&_a=(columns:!(_source),index:'*-*',interval:h,query:(query_string:(query:'grafana-paas.cloudapps.digital%20AND%20NOT%20access.response_code:200')),sort:!('@timestamp',desc))"
        runbook: "https://re-team-manual.cloudapps.digital/observe-support.html#re-observe-grafana-down"
  - alert: RE_Observe_AlertManager_Below_Threshold
    expr: up{job="alertmanager"} == 0 and ignoring(instance) sum without(instance) (up{job="alertmanager"}) <= 1
    for: 10s
    labels:
        product: "prometheus"
        severity: "page"
    annotations:
        summary: "Service is below the expected instance Threshold"
        description: "The service name is {{ $labels.job }}. The URL experiencing the issue is {{ $labels.instance }}."
        runbook: "https://re-team-manual.cloudapps.digital/observe-support.html#re-observe-alertmanager-below-threshold"
  - alert: RE_Observe_Prometheus_Below_Threshold
    expr: up{job="prometheus"} == 0 and ignoring(instance) sum without(instance) (up{job="prometheus"}) <= 1
    for: 10s
    labels:
        product: "prometheus"
        severity: "page"
    annotations:
        summary: "Service is below the expected instance Threshold"
        description: "The service name is {{ $labels.job }}. The URL experiencing the issue is {{ $labels.instance }}."
        runbook: "https://re-team-manual.cloudapps.digital/observe-support.html#re-observe-prometheus-below-threshold"
  - alert: RE_Observe_PrometheusDiskPredictedToFill
    expr: predict_linear(node_filesystem_avail{ mountpoint="/mnt", job="prometheus_node" }[12h], 3 * 86400) <= 0
    labels:
        product: "prometheus"
        severity: "ticket"
    annotations:
        summary: "Instance {{ $labels.instance }} disk {{ $labels.mountpoint }} is predicted to fill in 72h"
        runbook: "https://re-team-manual.cloudapps.digital/observe-support.html#re-observe-prometheus-disk-predicted-to-fill"
  - alert: RE_Observe_No_FileSd_Targets
    # Notes:
    # - this alert will only fire if there are *no* file_sd targets.
    # This is useful if we only have one source of file_sd config, but might not be
    # if we have multiple ways of receiving file_sd configs and only one of them breaks.
    expr: absent(prometheus_sd_file_timestamp)
    for: 10s
    labels:
        product: "prometheus"
        severity: "page"
    annotations:
        summary: "No file_sd targets detected"
        description: "No file_sd targets were detected.  Is there a problem accessing the targets bucket?"
        runbook: "https://re-team-manual.cloudapps.digital/observe-support.html#re-observe-no-filesd-targets"


# this can be improved however maybe this is something we need to focus on in Q2 when working on the support plan

  - alert: RE_Observe_Prometheus_Over_Capacity
    expr: sum without(slice)(rate(prometheus_engine_query_duration_seconds_sum{job="prometheus"}[5m])) > 8
    for: 10s
    labels:
        product: "prometheus"
        severity: "page"
    annotations:
        summary: "Service is over capacity."
        description: "The service name is {{ $labels.job }}. The URL experiencing the issue is {{ $labels.instance }}."
        runbook: "https://re-team-manual.cloudapps.digital/observe-support.html#re-observe-prometheus-over-capacity"

  - alert: RE_Observe_Prometheus_High_Load
    expr: sum without(slice)(rate(prometheus_engine_query_duration_seconds_sum{job="prometheus"}[2h])) > 4
    labels:
        product: "prometheus"
        severity: "ticket"
    annotations:
        summary: "Service is approaching capacity."
        description: "The service name is {{ $labels.job }}. The URL experiencing the issue is {{ $labels.instance }}."
        runbook: "https://re-team-manual.cloudapps.digital/observe-support.html#re-observe-prometheus-high-load"

  - alert: RE_Observe_Target_Down
    expr: up{} == 0
    for: 24h
    labels:
        product: "prometheus"
        severity: "ticket"
    annotations:
        summary: "{{ $labels.job }} target is down"
        description: "One of the {{ $labels.job }} targets has been down for 24 hours"
        runbook: "https://re-team-manual.cloudapps.digital/observe-support.html#re-observe-target-down"
